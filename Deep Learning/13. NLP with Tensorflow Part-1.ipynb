{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "1. Character Level Modelling\n",
    "- Stateless RNN\n",
    "- Stateful RNN\n",
    "2. Word Level Modelling\n",
    "3. Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(tf.__version__)\n",
    "def cls():\n",
    "    tf.random.set_seed(42)\n",
    "    tf.keras.backend.clear_session()\n",
    "cls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Character level Modelling \n",
    "We try to generate next character of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Lets download some shakespeare data. #\n",
    "########################################\n",
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets save this text\n",
    "shakespeare_text_path = \"datasets/shakespear_text.txt\"\n",
    "with open(shakespeare_text_path, \"w\") as text_file:\n",
    "    text_file.write(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# First few lines\n",
    "print(shakespeare_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\n",
      "Total length:  39\n"
     ]
    }
   ],
   "source": [
    "# These are the only unique characters used in text\n",
    "print(\"\".join(sorted(set(shakespeare_text.lower()))))\n",
    "print(\"Total length: \", len(\"\".join(sorted(set(shakespeare_text.lower())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique character:  41\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Convert each character to integer number #\n",
    "############################################\n",
    "cls()\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
    "                                                   standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "\n",
    "print(\"Unique character: \", text_vec_layer.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in text file:  (1115394,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([21,  7, 10,  9,  4,  2, 20,  7,  4,  7], dtype=int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = text_vec_layer([shakespeare_text])[0]\n",
    "print(\"Total Characters in text file: \", encoded.shape)\n",
    "encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see total unique element in text file according to tf is 41\n",
    "# while actually it is 39\n",
    "# so, we need to drop 2 other elements which is token 0 (pad) and 1 (unknown)\n",
    "# these are the most frequent elements that why its position at 0 and 1\n",
    "encoded -= 2  # drop tokens 0 (pad) and 1 (unknown), which we will not use\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct chars = 39\n",
    "dataset_size = len(encoded)  # total number of chars = 1,115,394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Stateless RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq dataset creation\n",
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 4,  5,  2, 23]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 5,  2, 23,  3]], dtype=int64)>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only one sample\n",
    "# input  : To be\n",
    "# target : o be \n",
    "dataset = to_dataset(text_vec_layer([\"To be\"])[0], length=4)\n",
    "list(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  ['t', 'o', ' ', 'b']\n",
      "Output:  ['o', ' ', 'b', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(\"Input : \", [text_vec_layer.get_vocabulary()[i] for i in list(dataset.take(1))[0][0].numpy()[0]])\n",
    "\n",
    "print(\"Output: \", [text_vec_layer.get_vocabulary()[i] for i in list(dataset.take(1))[0][1].numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset prepartion\n",
    "# we have total 1_115_394 characters\n",
    "# lets split df into train, valid, test\n",
    "length = 50 # this would be the single instance length\n",
    "cls()\n",
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True,seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(32, 50), dtype=int64, numpy=\n",
       "  array([[15,  0,  9, ...,  1,  8, 30],\n",
       "         [25,  1,  0, ..., 13, 14,  0],\n",
       "         [13,  7, 23, ...,  0,  5,  9],\n",
       "         ...,\n",
       "         [25,  1,  0, ...,  0,  4,  0],\n",
       "         [11, 12,  0, ..., 12,  0,  6],\n",
       "         [ 1,  0,  5, ...,  7,  0,  4]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(32, 50), dtype=int64, numpy=\n",
       "  array([[ 0,  9,  3, ...,  8, 30, 10],\n",
       "         [ 1,  0,  3, ..., 14,  0, 16],\n",
       "         [ 7, 23, 10, ...,  5,  9,  0],\n",
       "         ...,\n",
       "         [ 1,  0, 21, ...,  4,  0,  8],\n",
       "         [12,  0, 15, ...,  0,  6,  5],\n",
       "         [ 0,  5,  2, ...,  0,  4,  0]], dtype=int64)>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we can see our data is in decimal number so we need to make \n",
    "# it as an One-Hot or Embedding number.\n",
    "list(train_set.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our input would be 32,100 where 32 batch size, 50 time step\n",
    "# our output would be 32,100 where 32 batch size, 50 time step\n",
    "# as we can see when input is 15,0,9 then output => 0,9,3... so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(32, 50, 39), dtype=float32, numpy=\n",
       "  array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [1., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 1., ..., 0., 0., 0.]],\n",
       "  \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [1., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 1., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       "  \n",
       "         [[0., 1., 0., ..., 0., 0., 0.],\n",
       "          [1., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 1., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [1., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0., 1., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 1., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 1., ..., 0., 0., 0.]],\n",
       "  \n",
       "         [[0., 1., 0., ..., 0., 0., 0.],\n",
       "          [1., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       "  \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 50), dtype=int64, numpy=\n",
       "  array([[ 7, 17,  0, ...,  0,  2,  3],\n",
       "         [15,  0, 14, ..., 14, 22, 11],\n",
       "         [ 0,  1, 12, ...,  0, 11,  5],\n",
       "         ...,\n",
       "         [25,  1,  8, ...,  9,  2,  0],\n",
       "         [ 0, 16,  5, ...,  7,  6,  4],\n",
       "         [10, 10, 25, ...,  3, 24,  1]], dtype=int64)>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let do it first using One-Hot Encoding\n",
    "\n",
    "train_set_oh = train_set.map(lambda x,y: (tf.one_hot(x,depth=n_tokens), y)) \n",
    "valid_set_oh = valid_set.map(lambda x,y: (tf.one_hot(x,depth=n_tokens), y)) \n",
    "test_set_oh  = test_set.map(lambda x,y: (tf.one_hot(x,depth=n_tokens), y)) \n",
    "\n",
    "list(train_set_oh.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Each time step has 39 features: mean it will fire where 1 occur (place of character)\n",
    "# So in input layer there would be 39 neurons. bcz there is only 39\n",
    "# distinct values.\n",
    "\n",
    "# Similarly there would be 39 value in output layer bcz there is \n",
    "# 39 distinct value each neuron represent the probability of each number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, None, 32)          7008      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, None, 16)          2400      \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 39)         663       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,071\n",
      "Trainable params: 10,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let build the neural net using One-Hot\n",
    "cls()\n",
    "model = tf.keras.Sequential([ # from tf version 2.8.x\n",
    "    tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, n_tokens], dropout=0.2, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.GRU(16, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_tokens, activation=\"softmax\"))\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# WARNING: This simple model may take one hour to train #\n",
    "# Because our training data is large                    #\n",
    "#########################################################\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "            optimizer=\"nadam\",\n",
    "            metrics=[\"accuracy\"])\n",
    "#model_ckpt = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "history = model.fit(train_set_oh, validation_data=train_set_oh, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          624       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 128)         56064     \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 39)          5031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,719\n",
      "Trainable params: 61,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let build the neural net using embedding layer\n",
    "cls()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "#history = model.fit(train_set, validation_data=valid_set, epochs=10,callbacks=[model_ckpt])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, None)             0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, None)              0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, 39)          61719     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,719\n",
      "Trainable params: 61,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cls()\n",
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
    "    model\n",
    "])\n",
    "shakespeare_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/girraj.jangid/.keras/datasets/shakespeare_model')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# Lets download the trained model\n",
    "url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
    "path = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url, extract=True)\n",
    "model_path = Path(path).with_name(\"shakespeare_model\")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:An attribute in the restored object could not be found in the checkpoint. Object: (root).layer_with_weights-0._lookup_layer.token_counts, attribute: ['table']\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, None)             0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " lambda_5 (Lambda)           (None, None)              0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, 39)          61719     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,719\n",
      "Trainable params: 61,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cls()\n",
    "shakespeare_model = tf.keras.models.load_model(model_path)\n",
    "shakespeare_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 559ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 17, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = shakespeare_model.predict([\"To be or not to b\"])\n",
    "y_proba.shape # One instance 17 character each predict probability of 39 character\n",
    "# We only need last time step prediction so their would be only 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(17,), dtype=int64, numpy=\n",
       "array([ 6,  0,  2,  1,  0,  2,  9, 12,  9,  3,  2,  0,  7,  6,  0,  2,  1],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.argmax(y_proba[0],axis=1)  # choose the most probable character ID\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vocab(lst):\n",
    "    return print(''.join([text_vec_layer.get_vocabulary()[i] for i in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h te tndnot sh te\n"
     ]
    }
   ],
   "source": [
    "print_vocab(y_pred+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only care about last character bcz remaining we already know\n",
    "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
    "y_pred = tf.argmax(y_proba)  # choose the most probable character ID\n",
    "text_vec_layer.get_vocabulary()[y_pred + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50), dtype=int64, numpy=\n",
       "array([[0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 2, 0, 0, 1]], dtype=int64)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "# Let generate some fake text #\n",
    "###############################\n",
    "# As in practice, if we feed predicted value again in model then it\n",
    "# turn out to repeat the same value as prediction. \n",
    "#\n",
    "#\n",
    "\n",
    "# log values of 50, 40, 10%\n",
    "log_probas = tf.math.log([[0.5, 0.4, 0.1]])#probas = 50%, 40%, and 10%\n",
    "# This will draw num_samples from log_probas probability distribution\n",
    "# as you can see 50% values in output are 1\n",
    "# 40% values in output is 0\n",
    "# 10% values in output is 2\n",
    "tf.random.categorical(log_probas, num_samples=50)  # draw 8 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    # 39 probability\n",
    "    y_proba = shakespeare_model.predict([text],verbose=False)[0, -1:]\n",
    "    # Make distribution of 39 log prob samples\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    # take some random value from that distribution\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
    "    return text_vec_layer.get_vocabulary()[char_id + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to be the duke\n",
      "as it is a proper strange death,\n",
      "and then the sea to the death, and the duke and the death,\n",
      "and then the sea to the death, and the duke and the death,\n",
      "and then the sea to the death, and the duke and the death,\n",
      "and then the sea to the death, and the duke and the death,\n",
      "and then the strange daughter is a strange daughter,\n",
      "and the death and the death, and the death,\n",
      "and then the sea to the death, and the duke and the death,\n",
      "and then the strange daughter is a strange daughter,\n",
      "and the deat\n"
     ]
    }
   ],
   "source": [
    "cls()\n",
    "# Temperature will near to 0 favor high probability character\n",
    "# while very high value give all characters equaly value\n",
    "text = extend_text(\"To be or not to be\", n_chars=500, temperature=0.01)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to be win their joience\n",
      "shall bear, you will ne'er affe\n"
     ]
    }
   ],
   "source": [
    "text = extend_text(\"To be or not to be\", n_chars=50, temperature=1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to bewnxsukeqz r,we\n",
      "gj'kfb!i'x-a :ndp;mq.t3iprkfdlxkzu.\n"
     ]
    }
   ],
   "source": [
    "text = extend_text(\"To be or not to be\", n_chars=50, temperature=100)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Stateful RNN:\n",
    "Till now, At each training iteration the model starts with hidden state\n",
    "full of zeros, then it updates this state at each time step,\n",
    "and after the last time step,  it throws it away, as it is not\n",
    "needed anymore. what if we told the RNN to preserve this final\n",
    "state after preprocessing one training batch and use it as the initial\n",
    "state for the next training batch this way the model can learn\n",
    "long term pattern despite only backpropagation through short sequences\n",
    "this is called a `stateful RNN`.\n",
    "\n",
    "Stateful RNN only make sense when each input sequence in a batch starts exactly where the corresponding sequence in the previous batch left off. i.e. Non-overlapping sequence need to prepare rather than shuffled and overlapped sequences we used to train stateless RNN.\n",
    "\n",
    "We must use shift=n_step instead of shift=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset_for_stateful_rnn(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    # must set shift=length for non-overlapping\n",
    "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
    "    # Use batch 1 bcz each batchs first value would \n",
    "    # be next of previous batchs last value\n",
    "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 50\n",
    "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
    "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
    "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[0, 1, 2]])>,\n",
       "  <tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[1, 2, 3]])>),\n",
       " (<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[3, 4, 5]])>,\n",
       "  <tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[4, 5, 6]])>),\n",
       " (<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[6, 7, 8]])>,\n",
       "  <tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[7, 8, 9]])>)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(to_dataset_for_stateful_rnn(tf.range(10), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to have more then 1 instance then \n",
    "def to_non_overlapping_windows(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
    "    return ds.flat_map(lambda window: window.batch(length + 1))\n",
    "\n",
    "def to_batched_dataset_for_stateful_rnn(sequence, length, batch_size=32):\n",
    "    parts = np.array_split(sequence, batch_size)\n",
    "    datasets = tuple(to_non_overlapping_windows(part, length) for part in parts)\n",
    "    ds = tf.data.Dataset.zip(datasets).map(lambda *windows: tf.stack(windows))\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[ 0,  1,  2],\n",
       "         [10, 11, 12]])>,\n",
       "  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[ 1,  2,  3],\n",
       "         [11, 12, 13]])>),\n",
       " (<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[ 3,  4,  5],\n",
       "         [13, 14, 15]])>,\n",
       "  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[ 4,  5,  6],\n",
       "         [14, 15, 16]])>),\n",
       " (<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[ 6,  7,  8],\n",
       "         [16, 17, 18]])>,\n",
       "  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[ 7,  8,  9],\n",
       "         [17, 18, 19]])>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(to_batched_dataset_for_stateful_rnn(tf.range(20), length=3, batch_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# 1. While buildling the model we must specify batch_input_shape\n",
    "# because it will preserve a state for each input sequence in \n",
    "# the batch\n",
    "# 2. must use stateful=True in RNN layer\n",
    "##################################################################\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16,\n",
    "                              batch_input_shape=[1, None]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of epoch need to reset the state of batch\n",
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_stateful_shakespeare_model\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: This code will take more than hour to run.\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(stateful_train_set, validation_data=stateful_valid_set,\n",
    "                    epochs=10, callbacks=[ResetStatesCallback(), model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During prediction we must have to pass same batch size\n",
    "# to overcome this problem we can convert stateful RNN to stateless RNN\n",
    "# after training. Just need to copy the weights\n",
    "\n",
    "# Creating the dump model of stateful.\n",
    "stateless_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None]))\n",
    "stateless_model.set_weights(model.get_weights()) # stateful RNN is model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
    "    stateless_model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be or not to be;aohdjj?cbtbxri,m?fch,?y!.&kkb,pdj33h&yp$,jrm'snws\n"
     ]
    }
   ],
   "source": [
    "print(extend_text(\"to be or not to be\", temperature=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word Level Modelling\n",
    "We will built a sentiment analysis model using IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_train_set, raw_valid_set, raw_test_set),info = tfds.load(name=\"imdb_reviews\",split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],as_supervised=True, with_info=True)\n",
    "# Lets use keras dataset\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000) # read only top 10000 word occured\n",
    "# word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# x_valid, y_valid = x_test[:10_000], y_test[:10_000]\n",
    "# x_test, y_test = x_test[10_000:], y_test[10_000:]\n",
    "# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=20000>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=2500>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=2500>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_set.cardinality(), raw_valid_set.cardinality(), raw_test_set.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "for review, label in raw_train_set.take(1):\n",
    "    print(review.numpy().decode(\"utf-8\")[:200], \"...\")\n",
    "    print(\"Label:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls()\n",
    "batch_size = 12\n",
    "train_set = raw_train_set.shuffle(5000, seed=42).batch(batch_size).prefetch(1)\n",
    "valid_set = raw_valid_set.batch(batch_size).prefetch(1)\n",
    "test_set = raw_test_set.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'This is a documentary that came out of the splendid work of a Canadian landscape photographer whose interest has long been in the ravages left on earth by the excavations or buildings of man. It begin'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First instance of first batch\n",
    "list(train_set.take(1))[0][0][0].numpy()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build vocabulary of most occured 1000 words\n",
    "vocab_size = 1_000\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews)) # passing only reviews not label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'and', 'a']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer.get_vocabulary()[:5]\n",
    "# '', [UNK] are the most occured words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(194,), dtype=int64, numpy=\n",
       "array([  1,   7,  11,   1,   8, 188,   1,   4,   1,   5,   1,  12, 156,\n",
       "        58,   2,   1, 454,   4,   1,   1,  16,   1,   1, 295,   1,   1,\n",
       "       672, 383,   2, 165, 214,  28, 255,   8,   2, 430,   1,   1, 958,\n",
       "        60, 267, 101,   1,   6, 921,  17,  28, 247,  45,   4, 166,  97,\n",
       "         5,   1,  24,   1,   1,   1, 440,   1, 674, 154,   1,   1,  12,\n",
       "         1,   1,   7,   6, 937,  49,   1,   1,  14,   6,   1,   1,   8,\n",
       "         1, 663,   1,   1,   2, 198,   1,  37,   2, 242, 204, 255,   4,\n",
       "       219, 171, 324,   1,   8,  11, 521,   3,   1, 105, 149, 296,   5,\n",
       "         1,   1,   1, 384, 313, 304, 643, 384,   1,  12,   1, 669,   1,\n",
       "         1,   1,   6,  34, 606,   1,  33,   1,   1,   1,  55, 498, 133,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,  50,  29,  23,\n",
       "       325,   4,   1, 863, 597,   1,  58,  11, 735,  17,   4, 544,   5,\n",
       "         1,  16,  11,   1,   1, 339,   3,  44,  23,  57,  39,  23,  69,\n",
       "       130,   4,   1,   1,  12, 937, 145, 852,  11,   1,   3,  79, 141,\n",
       "       720,  39,   4,  18,   1,   5,   1,   3,   1,   1,   1,   1],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_vector = text_vec_layer(list(train_set.take(1))[0][0][0])\n",
    "seq_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(194, 128), dtype=float32, numpy=\n",
       "array([[ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "         0.03332629,  0.02803668],\n",
       "       [ 0.02248487, -0.02848336,  0.04786098, ...,  0.03069806,\n",
       "        -0.04317403, -0.04145076],\n",
       "       [-0.02399485,  0.01468222,  0.00041829, ...,  0.02498427,\n",
       "        -0.02674054, -0.00808267],\n",
       "       ...,\n",
       "       [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "         0.03332629,  0.02803668],\n",
       "       [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "         0.03332629,  0.02803668],\n",
       "       [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "         0.03332629,  0.02803668]], dtype=float32)>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we already discussed-\n",
    "# There are two option to normalize this decimal numbers\n",
    "# 1. via One-Hot-Enconding [Need to be 1000 neurons or 1000 dim data]\n",
    "# 2. Embedding Layer [tunable neuron]\n",
    "# \n",
    "cls()\n",
    "# Embedding layer has one row for one word i.e. \n",
    "# there are 194 word in sentence\n",
    "tf.keras.layers.Embedding(vocab_size,128)(seq_to_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667/1667 [==============================] - 369s 219ms/step - loss: 0.6929 - accuracy: 0.5095 - val_loss: 0.6928 - val_accuracy: 0.4944\n"
     ]
    }
   ],
   "source": [
    "# Embed size is hyper parameter you can tune it\n",
    "embed_size = 128\n",
    "cls()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_size),\n",
    "    tf.keras.layers.GRU(12),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking\n",
    "When we need to ignore some words like padding tokens. Then we can use mask concept. This layer will propagate mask dataset (boolean dataset where 1 is set at padding position in time step and 0 at other time steps). So, the all recurrent layers will ignore the masked time step. Basically recurrent cells hidden state will transfer the previous state to the next state when it encounter masked time step. There would be no loss contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To work this properly all layer should support masking\n",
    "# \n",
    "#\n",
    "embed_size = 128\n",
    "cls()\n",
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, None)        0           ['input_1[0][0]']                \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 128)    128000      ['text_vectorization[9][0]']     \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, None)        0           ['text_vectorization[9][0]']     \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, None, 128)    99072       ['embedding[0][0]',              \n",
      "                                                                  'tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 128)          99072       ['gru[0][0]',                    \n",
      "                                                                  'tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            129         ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 326,273\n",
      "Trainable params: 326,273\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# Custom masking Using Functional Model #\n",
    "#########################################\n",
    "\n",
    "cls()\n",
    "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "token_ids = text_vec_layer(inputs)\n",
    "mask = tf.math.not_equal(token_ids, 0)\n",
    "Z = tf.keras.layers.Embedding(vocab_size, embed_size)(token_ids)\n",
    "Z = tf.keras.layers.GRU(128, return_sequences=True, dropout=0.2)(Z, mask=mask)\n",
    "Z = tf.keras.layers.GRU(128, dropout=0.2)(Z, mask=mask)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(Z)\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
       "array([[ 86,  18,   0,   0,   0],\n",
       "       [ 11,   7,   1, 116, 214]], dtype=int64)>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This was created using Tensor\n",
    "text_vec_layer([\"Great movie!\", \"This is dicaprio's best role.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create vis ragged Tensor\n",
    "text_vec_layer_ragged = tf.keras.layers.TextVectorization(max_tokens=vocab_size, ragged=True)\n",
    "text_vec_layer_ragged.adapt(train_set.map(lambda reviews, labels: reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[86, 18], [11, 7, 1, 116, 214]]>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can observe in Ragged tensor our matrix in not proper 2D.\n",
    "text_vec_layer_ragged([\"Great movie!\", \"This is DiCaprio's best role.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667/1667 [==============================] - 600s 359ms/step - loss: 0.5826 - accuracy: 0.6875 - val_loss: 0.4849 - val_accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "# The embedding layer will take care about ragged tensor or tensor\n",
    "embed_size = 5\n",
    "cls()\n",
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer_ragged,\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_size),\n",
    "    tf.keras.layers.GRU(2),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reusing Pretrained Embeddings and Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# This is change the directory from temp to my_tfhub_cache\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"./datasets/my_tfhub_cache\"\n",
    "cls()\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", trainable=False, dtype=tf.string, input_shape=[]),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667/1667 [==============================] - 45s 25ms/step - loss: 0.3642 - accuracy: 0.8447 - val_loss: 0.3290 - val_accuracy: 0.8548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ada4752910>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, validation_data=valid_set, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
