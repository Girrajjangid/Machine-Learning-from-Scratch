{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Gradient Vanishing/Exploding Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def cls():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, sigmoid(z), \"b-\", linewidth=2,label=r\"$\\sigma(z) = \\dfrac{1}{1+e^{-z}}$\")\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props,fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props,fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(loc=\"upper left\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-1. Weight Initializer\n",
    "Xavier & He Initilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can initialize He by kernel_initializer=he_normal or he_uniform\n",
    "# By default it is initialize as glorat or xavier\n",
    "dense = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "\n",
    "# If you want to use variance scaling on weights\n",
    "he_avg_init = tf.keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\", distribution=\"uniform\")\n",
    "dense = tf.keras.layers.Dense(50, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-2. Non Saturating Activation Function\n",
    "Relu, sigmoid are the activation function which derivative saturates to 0 when its value extreme high or extreme low.\n",
    "We will discuss some non saturated activation functions here.\n",
    "\n",
    "### A-2-1. Leaky RELU (Rectified Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def leaky_relu(z, alpha):\n",
    "    return np.maximum(alpha * z, z)\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "plt.plot(z, leaky_relu(z, 0.1), \"b-\", linewidth=2, label=r\"$LeakyReLU(z) = max(\\alpha z, z)$\")\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-1, 3.7], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.3), arrowprops=props,fontsize=14, ha=\"center\")\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.axis([-5, 5, -1, 3.7])\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)  # defaults to alpha=0.3\n",
    "dense = tf.keras.layers.Dense(50, activation=leaky_relu, kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to define activation seperately when we use while building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # [...]  # more layers\n",
    "    tf.keras.layers.Dense(50, kernel_initializer=\"he_normal\"),  # no activation\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.2),  # activation as a separate layer\n",
    "    # [...]  # more layers\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2-2. ELU (Exponential Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation=\"elu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2-3. SELU (Scaled ELU)\n",
    "\n",
    "> By default, the SELU hyperparameters (**scale** and **alpha**) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too, and other constraints are respected, as explained in the book). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:\n",
    "\n",
    "- It will perform best when we use it with lecun_uniform/lecun_normal weight initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1 / np.sqrt(2)) * np.exp(1 / 2) - 1)\n",
    "scale_0_1 = (\n",
    "    (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e))\n",
    "    * np.sqrt(2 * np.pi)\n",
    "    * (\n",
    "        2 * erfc(np.sqrt(2)) * np.e ** 2\n",
    "        + np.pi * erfc(1 / np.sqrt(2)) ** 2 * np.e\n",
    "        - 2 * (2 + np.pi) * erfc(1 / np.sqrt(2)) * np.sqrt(np.e)\n",
    "        + np.pi\n",
    "        + 2\n",
    "    ) ** (-1 / 2)\n",
    ")\n",
    "\n",
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "\n",
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2, label=r\"ELU$_\\alpha(z) = \\alpha (e^z - 1)$ if $z < 0$, else $z$\")\n",
    "plt.plot(z, selu(z), \"r--\", linewidth=2, label=r\"SELU$(z) = 1.05 \\, $ELU$_{1.67}(z)$\")\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k:', linewidth=2)\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k:', linewidth=2)\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-3. Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cls()\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                    tf.keras.layers.BatchNormalization(),\n",
    "                                    tf.keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                    tf.keras.layers.BatchNormalization(),\n",
    "                                    tf.keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                    tf.keras.layers.BatchNormalization(),\n",
    "                                    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2368 are non-trainable params\n",
    "# First BN layer adds 3136 which is 4*784. [For a 28*28 there will be 784 features. each feature have sigma, mu, gamma, and beta param for BN]\n",
    "# Second BN layer adds 1200\n",
    "# Third BN layer adds 400\n",
    "# total would be = 3136+1200+400 = 4736 and divide by 2 --> 2368 [ Because sigma, mu are moving mean and std they will not train in backpropagation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check params\n",
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28) (6000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Lets load some data\n",
    "from sklearn.model_selection import train_test_split\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1)\n",
    "x_train, x_valid, x_test = x_train / 255, x_valid / 255, x_test / 255\n",
    "print(x_train.shape, x_valid.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.5516 - accuracy: 0.8082 - val_loss: 0.4345 - val_accuracy: 0.8470\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.4218 - accuracy: 0.8521 - val_loss: 0.3975 - val_accuracy: 0.8623\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'], optimizer=\"sgd\")\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.4363 - accuracy: 0.8424 - val_loss: 0.3650 - val_accuracy: 0.8678\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3523 - accuracy: 0.8715 - val_loss: 0.3415 - val_accuracy: 0.8773\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'], optimizer=\"adam\")\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a *BatchNormalization layer* does not need to have bias terms, since the BatchNormalization layer some as well, it would be a waste of parameters, so you can set *use_bias=False* when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.4818 - accuracy: 0.8284 - val_loss: 0.3988 - val_accuracy: 0.8540\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3868 - accuracy: 0.8598 - val_loss: 0.3712 - val_accuracy: 0.8668\n"
     ]
    }
   ],
   "source": [
    "# When we want to use BN layer before the activation layers\n",
    "cls()\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                    tf.keras.layers.BatchNormalization(),\n",
    "                                    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "                                    tf.keras.layers.BatchNormalization(),\n",
    "                                    tf.keras.layers.ELU(),\n",
    "                                    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "                                    tf.keras.layers.BatchNormalization(),\n",
    "                                    tf.keras.layers.Activation(\"elu\"),\n",
    "                                    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'], optimizer=\"adam\")\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-4. Gradiant Clipping\n",
    "Used to clip the gradient when it exceed the passed value. It will help in Gradient exploding problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "# Both are same\n",
    "optimizer = tf.keras.optimizers.SGD(clipnorm=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Reusing Pretrained Layers\n",
    "How to use pretrained custom layers, and fully trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's split the fashion MNIST training set in two:\n",
    "\n",
    "- X_train_A: all images of all items except for T-shirts/tops and pullovers (classes 0 and 2). [Only total 8 classes].\n",
    "- X_train_B: a much smaller training set of just the first 200 images of T-shirts/tops and pullovers.\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "> We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots) are somewhat similar to classes in set B (T-shirts/tops and pullovers). However, since we are using Dense layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28) (6000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Lets load some data\n",
    "from sklearn.model_selection import train_test_split\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1)\n",
    "x_train, x_valid, x_test = x_train / 255, x_valid / 255, x_test / 255\n",
    "print(x_train.shape, x_valid.shape, x_test.shape)\n",
    "\n",
    "# These are the 10 classes\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will split the dataset\n",
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set A:  (43220, 28, 28) (4780, 28, 28) (8000, 28, 28)\n",
      "Set B:  (200, 28, 28) (200,)\n"
     ]
    }
   ],
   "source": [
    "(x_train_A, y_train_A), (x_train_B, y_train_B) = split_dataset(x_train, y_train)\n",
    "(x_valid_A, y_valid_A), (x_valid_B, y_valid_B) = split_dataset(x_valid, y_valid)\n",
    "(x_test_A, y_test_A), (x_test_B, y_test_B) = split_dataset(x_test, y_test)\n",
    "x_train_B = x_train_B[:200]\n",
    "y_train_B = y_train_B[:200]\n",
    "\n",
    "print(\"Set A: \", x_train_A.shape, x_valid_A.shape, x_test_A.shape)\n",
    "print(\"Set B: \", x_train_B.shape, y_train_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes in Set A:  [0 1 2 3 4 5 6 7]\n",
      "Total classes in Set B:  [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total classes in Set A: \",np.unique(y_train_A))\n",
    "print(\"Total classes in Set B: \",np.unique(y_train_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.3180 - accuracy: 0.8851 - val_loss: 0.2504 - val_accuracy: 0.9130\n",
      "Epoch 2/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.2325 - accuracy: 0.9157 - val_loss: 0.2316 - val_accuracy: 0.9180\n",
      "Epoch 3/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.2002 - accuracy: 0.9266 - val_loss: 0.3342 - val_accuracy: 0.8931\n",
      "Epoch 4/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.1812 - accuracy: 0.9332 - val_loss: 0.2109 - val_accuracy: 0.9272\n",
      "Epoch 5/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.1679 - accuracy: 0.9387 - val_loss: 0.2109 - val_accuracy: 0.9264\n",
      "Epoch 6/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.1546 - accuracy: 0.9427 - val_loss: 0.1902 - val_accuracy: 0.9337\n",
      "Epoch 7/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.1470 - accuracy: 0.9466 - val_loss: 0.1954 - val_accuracy: 0.9364\n",
      "Epoch 8/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.1357 - accuracy: 0.9488 - val_loss: 0.1853 - val_accuracy: 0.9372\n",
      "Epoch 9/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.1287 - accuracy: 0.9515 - val_loss: 0.1950 - val_accuracy: 0.9343\n",
      "Epoch 10/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.1222 - accuracy: 0.9538 - val_loss: 0.2020 - val_accuracy: 0.9345\n",
      "INFO:tensorflow:Assets written to: model/my_model_A\\assets\n"
     ]
    }
   ],
   "source": [
    "# Building the model using set A and save it.\n",
    "cls()\n",
    "model_A = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(50,  activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "history = model_A.fit(x_train_A, y_train_A, epochs=10, validation_data=(x_valid_A, y_valid_A))\n",
    "model_A.save(\"model/my_model_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 38ms/step - loss: 0.6918 - accuracy: 0.7350 - val_loss: 0.1278 - val_accuracy: 0.9566\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2510 - accuracy: 0.9050 - val_loss: 0.1819 - val_accuracy: 0.9484\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2071 - accuracy: 0.9550 - val_loss: 0.1821 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1719 - accuracy: 0.9400 - val_loss: 0.1425 - val_accuracy: 0.9475\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1274 - accuracy: 0.9500 - val_loss: 0.1940 - val_accuracy: 0.9459\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1180 - accuracy: 0.9700 - val_loss: 0.1513 - val_accuracy: 0.9566\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.1125 - val_accuracy: 0.9582\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0829 - accuracy: 0.9650 - val_loss: 0.1199 - val_accuracy: 0.9582\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0682 - accuracy: 0.9750 - val_loss: 0.1490 - val_accuracy: 0.9549\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0574 - accuracy: 0.9750 - val_loss: 0.1097 - val_accuracy: 0.9615\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15540720522403717, 0.949999988079071]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model B on set-B without using model A\n",
    "cls()\n",
    "model_B = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(50,  activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_B.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "history = model_B.fit(x_train_B, y_train_B, epochs=10, validation_data=(x_valid_B, y_valid_B))\n",
    "model_B.evaluate(x_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-B gave 95% accuracy on test-B set\n",
    "\n",
    "# Now lets load model-A to use it with model-B\n",
    "# Remember model-A trained on 8 classes\n",
    "# model-B trained on 2 classes\n",
    "cls()\n",
    "model_A = tf.keras.models.load_model(\"model/my_model_A\")      # Trained model loaded\n",
    "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1]) # Excluded last layers as it contained 10 neurons\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\", name='output_layer')) # adding new layer with 1 neuron\n",
    "\n",
    "#Note that **model_B_on_A** and **model_A** actually share layers now, so when we train one, it will update both models. \n",
    "# If we want to avoid that, we need to build **model_B_on_A** on top of a clone of **model_A**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 270,701\n",
      "Trainable params: 270,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Same like we did in previous cell\n",
    "cls()\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\", name='output_layer'))\n",
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 270,701\n",
      "Trainable params: 51\n",
      "Non-trainable params: 270,650\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Only last layer we train\n",
    "for layers in model_B_on_A.layers[:-1]:\n",
    "    layers.trainable = False\n",
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0440 - accuracy: 0.9850 - val_loss: 0.1310 - val_accuracy: 0.9574\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0365 - accuracy: 0.9850 - val_loss: 0.1302 - val_accuracy: 0.9582\n",
      "Epoch 1/8\n",
      "7/7 [==============================] - 1s 34ms/step - loss: 0.4411 - accuracy: 0.8000 - val_loss: 0.1226 - val_accuracy: 0.9574\n",
      "Epoch 2/8\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0931 - accuracy: 0.9550 - val_loss: 0.1304 - val_accuracy: 0.9623\n",
      "Epoch 3/8\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0678 - accuracy: 0.9700 - val_loss: 0.1378 - val_accuracy: 0.9615\n",
      "Epoch 4/8\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0452 - accuracy: 0.9850 - val_loss: 0.1228 - val_accuracy: 0.9639\n",
      "Epoch 5/8\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0396 - accuracy: 0.9850 - val_loss: 0.1267 - val_accuracy: 0.9639\n",
      "Epoch 6/8\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.1489 - val_accuracy: 0.9607\n",
      "Epoch 7/8\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.1498 - val_accuracy: 0.9631\n",
      "Epoch 8/8\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.1415 - val_accuracy: 0.9623\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2104317992925644, 0.9539999961853027]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "history = model_B.fit(x_train_B, y_train_B, epochs=2, validation_data=(x_valid_B, y_valid_B))\n",
    "# To train lower layers\n",
    "for layers in model_B_on_A.layers[:-1]:\n",
    "    layers.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(x_train_B, y_train_B, epochs=8, validation_data=(x_valid_B, y_valid_B))\n",
    "model_B_on_A.evaluate(x_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.9840319361278445"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Net improvement\n",
    "(1 - (100 - 95.39) / (100 - 94.99)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model accuracy increase by 0.4 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(optimizer):\n",
    "    cls()\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        tf.keras.layers.Dense(300, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(100, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(50,  activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid)), model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track on results\n",
    "res = {'Optimizer':[], 'Score':[], \"Accuracy\":[]}\n",
    "result = lambda opt,sc,ac: (res['Optimizer'].append(opt), res['Score'].append(sc),res['Accuracy'].append(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 1.0607 - accuracy: 0.6518 - val_loss: 0.7671 - val_accuracy: 0.7512\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.6743 - accuracy: 0.7776 - val_loss: 0.6331 - val_accuracy: 0.7923\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5836 - accuracy: 0.8046 - val_loss: 0.5750 - val_accuracy: 0.8080\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5383 - accuracy: 0.8149 - val_loss: 0.5386 - val_accuracy: 0.8158\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5097 - accuracy: 0.8240 - val_loss: 0.5202 - val_accuracy: 0.8182\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.8151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5269959568977356, 0.8151000142097473]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "# 1. Stocastic Gradient Decent #\n",
    "################################\n",
    "history_sgd, model = build_model(tf.keras.optimizers.SGD(learning_rate=0.001))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('SGD',0.52,81.51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.6085 - accuracy: 0.7877 - val_loss: 0.4899 - val_accuracy: 0.8290\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4475 - accuracy: 0.8403 - val_loss: 0.4420 - val_accuracy: 0.8447\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4116 - accuracy: 0.8527 - val_loss: 0.4412 - val_accuracy: 0.8413\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3884 - accuracy: 0.8604 - val_loss: 0.4056 - val_accuracy: 0.8557\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3719 - accuracy: 0.8666 - val_loss: 0.3936 - val_accuracy: 0.8590\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4128953218460083, 0.8499000072479248]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "# 2. Momentum #\n",
    "###############\n",
    "history_sgd, model = build_model(tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Momentum',0.41,84.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.6023 - accuracy: 0.7914 - val_loss: 0.4869 - val_accuracy: 0.8293\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4435 - accuracy: 0.8421 - val_loss: 0.4435 - val_accuracy: 0.8432\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4088 - accuracy: 0.8535 - val_loss: 0.4311 - val_accuracy: 0.8462\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3865 - accuracy: 0.8611 - val_loss: 0.4031 - val_accuracy: 0.8585\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3699 - accuracy: 0.8669 - val_loss: 0.3862 - val_accuracy: 0.8635\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4039700925350189, 0.8546000123023987]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################\n",
    "# 3. Nestrov Accelerated Gradient #\n",
    "###################################\n",
    "history_sgd, model = build_model(tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Nestrov',0.40,85.46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.8143 - accuracy: 0.7339 - val_loss: 0.6150 - val_accuracy: 0.7987\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5546 - accuracy: 0.8132 - val_loss: 0.5378 - val_accuracy: 0.8180\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5031 - accuracy: 0.8276 - val_loss: 0.5074 - val_accuracy: 0.8265\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4774 - accuracy: 0.8340 - val_loss: 0.4848 - val_accuracy: 0.8328\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4601 - accuracy: 0.8406 - val_loss: 0.4739 - val_accuracy: 0.8352\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48414745926856995, 0.8281999826431274]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "# 4. AdaGrad #\n",
    "##############\n",
    "history_sgd, model = build_model(tf.keras.optimizers.Adagrad(learning_rate=1e-3))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('AdaGrad',0.48,82.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.5180 - accuracy: 0.8111 - val_loss: 0.4737 - val_accuracy: 0.8177\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3882 - accuracy: 0.8563 - val_loss: 0.3972 - val_accuracy: 0.8633\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3538 - accuracy: 0.8718 - val_loss: 0.4478 - val_accuracy: 0.8362\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3313 - accuracy: 0.8801 - val_loss: 0.3872 - val_accuracy: 0.8590\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3142 - accuracy: 0.8849 - val_loss: 0.3459 - val_accuracy: 0.8822\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37405630946159363, 0.8715000152587891]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "# 5. RMSProp #\n",
    "##############\n",
    "history_sgd, model = build_model(tf.keras.optimizers.RMSprop())\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('RMSProp',0.37,87.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4812 - accuracy: 0.8238 - val_loss: 0.4565 - val_accuracy: 0.8255\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3751 - accuracy: 0.8608 - val_loss: 0.3994 - val_accuracy: 0.8512\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3363 - accuracy: 0.8754 - val_loss: 0.3750 - val_accuracy: 0.8635\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3131 - accuracy: 0.8826 - val_loss: 0.3649 - val_accuracy: 0.8668\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2932 - accuracy: 0.8905 - val_loss: 0.3473 - val_accuracy: 0.8780\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3794373869895935, 0.8716999888420105]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########\n",
    "# 6. Adam #\n",
    "###########\n",
    "history_sgd, model = build_model(tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Adam',0.37,87.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4982 - accuracy: 0.8229 - val_loss: 0.4178 - val_accuracy: 0.8505\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3819 - accuracy: 0.8606 - val_loss: 0.3927 - val_accuracy: 0.8570\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3433 - accuracy: 0.8735 - val_loss: 0.3665 - val_accuracy: 0.8660\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3181 - accuracy: 0.8823 - val_loss: 0.3526 - val_accuracy: 0.8722\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3002 - accuracy: 0.8895 - val_loss: 0.3191 - val_accuracy: 0.8845\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3451217710971832, 0.8754000067710876]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############\n",
    "# 7. Adamax #\n",
    "#############\n",
    "history_sgd, model = build_model(tf.keras.optimizers.Adamax())\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Adamax',0.37,87.54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8798 - accuracy: 0.3628 - val_loss: 1.5537 - val_accuracy: 0.5090\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 1.3547 - accuracy: 0.5831 - val_loss: 1.2229 - val_accuracy: 0.6092\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 1.1167 - accuracy: 0.6442 - val_loss: 1.0513 - val_accuracy: 0.6593\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.9837 - accuracy: 0.6832 - val_loss: 0.9472 - val_accuracy: 0.6955\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.8975 - accuracy: 0.7120 - val_loss: 0.8759 - val_accuracy: 0.7212\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8791 - accuracy: 0.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8791443109512329, 0.7127000093460083]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "# 8. AdaDelta #\n",
    "###############\n",
    "history_sgd, model = build_model(tf.keras.optimizers.Adadelta())\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('AdaDelta',0.87,71.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.4746 - accuracy: 0.8261 - val_loss: 0.4515 - val_accuracy: 0.8335\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3586 - accuracy: 0.8675 - val_loss: 0.3773 - val_accuracy: 0.8620\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3213 - accuracy: 0.8815 - val_loss: 0.4002 - val_accuracy: 0.8550\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2992 - accuracy: 0.8871 - val_loss: 0.3611 - val_accuracy: 0.8685\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2799 - accuracy: 0.8943 - val_loss: 0.3321 - val_accuracy: 0.8838\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3569546341896057, 0.8758000135421753]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# 9. Nadam #\n",
    "############\n",
    "history_sgd, model = build_model(tf.keras.optimizers.Nadam())\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Nadam',0.35,87.58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.0-cp38-cp38-win_amd64.whl (758 kB)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.17.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4811 - accuracy: 0.8239 - val_loss: 0.4569 - val_accuracy: 0.8260\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3752 - accuracy: 0.8610 - val_loss: 0.4170 - val_accuracy: 0.8457\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3365 - accuracy: 0.8746 - val_loss: 0.3799 - val_accuracy: 0.8600\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3140 - accuracy: 0.8821 - val_loss: 0.3539 - val_accuracy: 0.8698\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2950 - accuracy: 0.8895 - val_loss: 0.3414 - val_accuracy: 0.8802\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37994199991226196, 0.8719000220298767]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############\n",
    "# 10. AdamW #\n",
    "#############\n",
    "import tensorflow_addons as tfa\n",
    "history_sgd, model = build_model(tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=0.001,beta_1=0.9, beta_2=0.999))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('AdamW',0.38,87.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.35</td>\n",
       "      <td>87.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.37</td>\n",
       "      <td>87.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.38</td>\n",
       "      <td>87.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.37</td>\n",
       "      <td>87.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>0.37</td>\n",
       "      <td>87.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nestrov</td>\n",
       "      <td>0.40</td>\n",
       "      <td>85.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Momentum</td>\n",
       "      <td>0.41</td>\n",
       "      <td>84.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaGrad</td>\n",
       "      <td>0.48</td>\n",
       "      <td>82.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.52</td>\n",
       "      <td>81.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaDelta</td>\n",
       "      <td>0.87</td>\n",
       "      <td>71.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Optimizer  Score  Accuracy\n",
       "0     Nadam   0.35     87.58\n",
       "1    Adamax   0.37     87.54\n",
       "2     AdamW   0.38     87.19\n",
       "3      Adam   0.37     87.17\n",
       "4   RMSProp   0.37     87.15\n",
       "5   Nestrov   0.40     85.46\n",
       "6  Momentum   0.41     84.99\n",
       "7   AdaGrad   0.48     82.81\n",
       "8       SGD   0.52     81.51\n",
       "9  AdaDelta   0.87     71.27"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(res).sort_values('Accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see-\n",
    "# There is 5% improvement in Accuracy just by changing optimizer from SGD varients' to Adam varients'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-1. Power Scheduling\n",
    "**lr = lr0 / (1 + steps / s)\\*\\*c**\n",
    "- Keras uses c=1 and s = 1 / decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track on results\n",
    "res = {'Optimizer':[], 'Score':[], \"Accuracy\":[], 'Decay':[]}\n",
    "result = lambda opt,sc,ac: (res['Optimizer'].append(\"SGD\"), res['Score'].append(sc),res['Accuracy'].append(ac),res['Decay'].append(opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.6071 - accuracy: 0.7891 - val_loss: 0.5128 - val_accuracy: 0.8117\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4525 - accuracy: 0.8391 - val_loss: 0.4505 - val_accuracy: 0.8420\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.4177 - accuracy: 0.8516 - val_loss: 0.4398 - val_accuracy: 0.8440\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3973 - accuracy: 0.8575 - val_loss: 0.4257 - val_accuracy: 0.8512\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3826 - accuracy: 0.8639 - val_loss: 0.3985 - val_accuracy: 0.8613\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4113 - accuracy: 0.8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41133520007133484, 0.8490999937057495]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_lr_power, model = build_model(tf.keras.optimizers.SGD(learning_rate=0.01, decay=1e-4))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Power S',0.41,84.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-2. Exponential Scheduling\n",
    "\n",
    "> lr = lr0 * 0.1 ** (epoch / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1 ** (epoch / 20)\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_m():\n",
    "    cls()\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        tf.keras.layers.Dense(300, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(100, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(50,  activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.6058 - accuracy: 0.7890 - val_loss: 0.5114 - val_accuracy: 0.8128\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4495 - accuracy: 0.8400 - val_loss: 0.4489 - val_accuracy: 0.8418\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4138 - accuracy: 0.8525 - val_loss: 0.4376 - val_accuracy: 0.8448\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3926 - accuracy: 0.8594 - val_loss: 0.4229 - val_accuracy: 0.8527\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3774 - accuracy: 0.8652 - val_loss: 0.3937 - val_accuracy: 0.8622\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4069 - accuracy: 0.8517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40694180130958557, 0.8517000079154968]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_m()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "cb_lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "h_lr_exp = model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid),callbacks=[cb_lr_scheduler])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_lr_exp.epoch, h_lr_exp.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, 5 - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimizer': ['SGD', 'SGD'],\n",
       " 'Score': [0.41, 0.4],\n",
       " 'Accuracy': [84.9, 85.17],\n",
       " 'Decay': ['Power S', 'Expon S']}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Expon S',0.40,85.17)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "\n",
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1 ** (1 / 5)\n",
    "\n",
    "class ExponentialDecay(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, n_steps=40_000):\n",
    "        super().__init__()\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
    "        new_learning_rate = lr * 0.1 ** (1 / self.n_steps)\n",
    "        K.set_value(self.model.optimizer.learning_rate, new_learning_rate)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.learning_rate)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.6100 - accuracy: 0.7889 - val_loss: 0.5134 - val_accuracy: 0.8132\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4577 - accuracy: 0.8382 - val_loss: 0.4578 - val_accuracy: 0.8403\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.4280 - accuracy: 0.8488 - val_loss: 0.4477 - val_accuracy: 0.8447\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.4135 - accuracy: 0.8529 - val_loss: 0.4334 - val_accuracy: 0.8477\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.4049 - accuracy: 0.8571 - val_loss: 0.4287 - val_accuracy: 0.8503\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4401775002479553, 0.840399980545044]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "model = build_m()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),metrics=[\"accuracy\"])\n",
    "n_steps   = 5 * math.ceil(len(x_train) / 32)\n",
    "exp_decay = ExponentialDecay(n_steps)\n",
    "history  = model.fit(x_train, y_train, epochs=5,validation_data=(x_valid, y_valid), callbacks=[exp_decay])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Expon S step',0.44,84.04)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The Nadam optimizer does not support tf.keras.optimizers.LearningRateSchedules as the learning rate.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-224-9101fe1c161e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscheduled_learning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExponentialDecay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_learning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mh_power_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNadam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscheduled_learning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\nadam.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, learning_rate, beta_1, beta_2, epsilon, name, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m       raise ValueError('The Nadam optimizer does not support '\n\u001b[0m\u001b[0;32m     70\u001b[0m                        \u001b[1;34m'tf.keras.optimizers.LearningRateSchedules as the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                        'learning rate.')\n",
      "\u001b[1;31mValueError\u001b[0m: The Nadam optimizer does not support tf.keras.optimizers.LearningRateSchedules as the learning rate."
     ]
    }
   ],
   "source": [
    "# Using Keras scheduler\n",
    "n_steps = 5 * math.ceil(len(x_train) / 32)\n",
    "scheduled_learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.01, decay_steps=n_steps, decay_rate=0.1)\n",
    "h_power_lr, model = build_model(tf.keras.optimizers.SGD(learning_rate=scheduled_learning_rate))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimizer': ['SGD', 'SGD', 'SGD', 'SGD'],\n",
       " 'Score': [0.41, 0.4, 0.44, 0.44],\n",
       " 'Accuracy': [84.9, 85.17, 84.04, 84.04],\n",
       " 'Decay': ['Power S', 'Expon S', 'Expon S step', 'Expon S keras']}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Expon S keras',0.44,84.04)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-3. Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "\n",
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[(boundaries > epoch).argmax() - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.6058 - accuracy: 0.7890 - val_loss: 0.5114 - val_accuracy: 0.8128\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4505 - accuracy: 0.8394 - val_loss: 0.4483 - val_accuracy: 0.8422\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4135 - accuracy: 0.8519 - val_loss: 0.4365 - val_accuracy: 0.8460\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3906 - accuracy: 0.8605 - val_loss: 0.4222 - val_accuracy: 0.8528\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3739 - accuracy: 0.8654 - val_loss: 0.3871 - val_accuracy: 0.8635\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40123504400253296, 0.8549000024795532]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_m()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "cb_lr_scheduler = tf.keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "h_exp_lr = model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid),callbacks=[cb_lr_scheduler])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.6058 - accuracy: 0.7890 - val_loss: 0.5114 - val_accuracy: 0.8128\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4505 - accuracy: 0.8394 - val_loss: 0.4483 - val_accuracy: 0.8422\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4135 - accuracy: 0.8519 - val_loss: 0.4365 - val_accuracy: 0.8460\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3906 - accuracy: 0.8605 - val_loss: 0.4222 - val_accuracy: 0.8528\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3739 - accuracy: 0.8654 - val_loss: 0.3871 - val_accuracy: 0.8635\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40123504400253296, 0.8549000024795532]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using keras scheduler\n",
    "n_steps_ = math.ceil(len(x_train) / 32)\n",
    "scheduled_learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[5. * n_steps_, 15. * n_steps_], values=[0.01, 0.005, 0.001])\n",
    "h_power_lr, model = build_model(tf.keras.optimizers.SGD(learning_rate=scheduled_learning_rate))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimizer': ['SGD', 'SGD', 'SGD', 'SGD', 'SGD', 'SGD'],\n",
       " 'Score': [0.41, 0.4, 0.44, 0.44, 0.4, 0.4],\n",
       " 'Accuracy': [84.9, 85.17, 84.04, 84.04, 85.5, 85.5],\n",
       " 'Decay': ['Power S',\n",
       "  'Expon S',\n",
       "  'Expon S step',\n",
       "  'Expon S keras',\n",
       "  'Piecewise D',\n",
       "  'Piecewise D Keras']}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Piecewise D',0.40,85.50)\n",
    "result('Piecewise D Keras',0.40,85.50)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-4. Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 1.0607 - accuracy: 0.6518 - val_loss: 0.7671 - val_accuracy: 0.7512\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.6743 - accuracy: 0.7776 - val_loss: 0.6331 - val_accuracy: 0.7923\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.5836 - accuracy: 0.8046 - val_loss: 0.5750 - val_accuracy: 0.8080\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.5383 - accuracy: 0.8149 - val_loss: 0.5386 - val_accuracy: 0.8158\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.5097 - accuracy: 0.8240 - val_loss: 0.5202 - val_accuracy: 0.8182\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.8151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5269959568977356, 0.8151000142097473]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_m()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "cb_lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)\n",
    "h_per_lr = model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid),callbacks=[cb_lr_scheduler])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('Performance S',0.52,81.51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_per_lr.epoch, h_per_lr.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, 5 - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(h_per_lr.epoch, h_per_lr.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-5. 1Cycle scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ExponentialLearningRate** custom callback updates the learning rate during training, at the end of each batch. It multiplies it by a constant **factor.** It also saves the learning rate and loss at each batch. Since **logs[\"loss\"]** is actually the mean loss since the start of the epoch, and we want to save the batch loss instead, we must compute the mean times the number of batches since the beginning of the epoch to get the total loss so far, then we subtract the total loss at the previous batch to get the current batch's loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "\n",
    "class ExponentialLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.sum_of_epoch_losses = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        mean_epoch_loss = logs[\"loss\"]  # the epoch's mean loss so far \n",
    "        new_sum_of_epoch_losses = mean_epoch_loss * (batch + 1)\n",
    "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
    "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(batch_loss)\n",
    "        K.set_value(self.model.optimizer.learning_rate,\n",
    "                    self.model.optimizer.learning_rate * self.factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **find_learning_rate()** function trains the model using the **ExponentialLearningRate** callback, and it returns the learning rates and corresponding batch losses. At the end, it restores the model and its optimizer to their initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=1e-4,\n",
    "                       max_rate=1):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = (max_rate / min_rate) ** (1 / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **plot_lr_vs_loss()** function plots the learning rates vs the losses. The optimal learning rate to use as the maximum learning rate in 1cycle is near the bottom of the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses, \"b\")\n",
    "    plt.gca().set_xscale('log')\n",
    "    max_loss = losses[0] + min(losses)\n",
    "    plt.hlines(min(losses), min(rates), max(rates), color=\"k\")\n",
    "    plt.axis([min(rates), max(rates), 0, max_loss])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.4196\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's build a simple Fashion MNIST model and compile it:\n",
    "model = build_m()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),metrics=[\"accuracy\"])\n",
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, x_train, y_train, epochs=1,batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the max learning rate to use for 1cycle is around 10–1.\n",
    "\n",
    "The **OneCycleScheduler** custom callback updates the learning rate at the beginning of each batch. It applies the logic described in the book: increase the learning rate linearly during about half of training, then reduce it linearly back to the initial learning rate, and lastly reduce it down to close to zero linearly for the very last part of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_lr=1e-3, start_lr=None,\n",
    "                 last_iterations=None, last_lr=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr,\n",
    "                                   self.max_lr)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                   self.max_lr, self.start_lr)\n",
    "        else:\n",
    "            lr = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                   self.start_lr, self.last_lr)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.7551 - accuracy: 0.7411 - val_loss: 0.5192 - val_accuracy: 0.8177\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.4955 - accuracy: 0.8213 - val_loss: 0.5181 - val_accuracy: 0.8120\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.4273 - accuracy: 0.8444 - val_loss: 0.4413 - val_accuracy: 0.8337\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3712 - accuracy: 0.8641 - val_loss: 0.3820 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.3444 - accuracy: 0.8751 - val_loss: 0.3717 - val_accuracy: 0.8688\n"
     ]
    }
   ],
   "source": [
    "model = build_m()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=tf.keras.optimizers.SGD(),metrics=[\"accuracy\"])\n",
    "onecycle = OneCycleScheduler(math.ceil(len(x_train) / batch_size) * 5,max_lr=0.1)\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=batch_size,validation_data=(x_valid, y_valid),callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result('OneCycle',0.49,82.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.40</td>\n",
       "      <td>85.50</td>\n",
       "      <td>Piecewise D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.40</td>\n",
       "      <td>85.50</td>\n",
       "      <td>Piecewise D Keras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.40</td>\n",
       "      <td>85.17</td>\n",
       "      <td>Expon S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.41</td>\n",
       "      <td>84.90</td>\n",
       "      <td>Power S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.44</td>\n",
       "      <td>84.04</td>\n",
       "      <td>Expon S step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.44</td>\n",
       "      <td>84.04</td>\n",
       "      <td>Expon S keras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.49</td>\n",
       "      <td>82.17</td>\n",
       "      <td>OneCycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.52</td>\n",
       "      <td>81.51</td>\n",
       "      <td>Performance S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Optimizer  Score  Accuracy              Decay\n",
       "0       SGD   0.40     85.50        Piecewise D\n",
       "1       SGD   0.40     85.50  Piecewise D Keras\n",
       "2       SGD   0.40     85.17            Expon S\n",
       "3       SGD   0.41     84.90            Power S\n",
       "4       SGD   0.44     84.04       Expon S step\n",
       "5       SGD   0.44     84.04      Expon S keras\n",
       "6       SGD   0.49     82.17           OneCycle\n",
       "7       SGD   0.52     81.51      Performance S"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "# Improvement using learning rate decays #\n",
    "##########################################\n",
    "# Raw SGD accuracy was 81%\n",
    "# Now you can see by changing learning rate it improved by 4%\n",
    "pd.DataFrame(res).sort_values('Accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Avoiding Overfitting Through Regularization\n",
    "### E-1. ℓ1 and ℓ2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(10, activation=\"relu\",kernel_initializer=\"he_normal\", kernel_regularizer=tf.keras.regularizers.L1(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use **l1(0.1)** for ℓ1 regularization with a factor of 0.1, or **l1_l2(0.1, 0.01)** for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you dont want to write each line again and again then partial from functools will help you\n",
    "from functools import partial\n",
    "RegularizedDense = partial(tf.keras.layers.Dense,activation=\"relu\",kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "cls()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 3.1458 - accuracy: 0.7750 - val_loss: 1.9387 - val_accuracy: 0.7908\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 1.4454 - accuracy: 0.8147 - val_loss: 1.1668 - val_accuracy: 0.8127\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 1.0303 - accuracy: 0.8171 - val_loss: 0.9849 - val_accuracy: 0.7965\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.9198 - accuracy: 0.8161 - val_loss: 0.9341 - val_accuracy: 0.7950\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.8857 - accuracy: 0.8179 - val_loss: 0.8870 - val_accuracy: 0.8115\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.02), metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-2. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.6758 - accuracy: 0.7521 - val_loss: 0.4526 - val_accuracy: 0.8315\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5109 - accuracy: 0.8129 - val_loss: 0.4221 - val_accuracy: 0.8430\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4721 - accuracy: 0.8264 - val_loss: 0.4188 - val_accuracy: 0.8410\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4494 - accuracy: 0.8340 - val_loss: 0.3848 - val_accuracy: 0.8585\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4351 - accuracy: 0.8372 - val_loss: 0.3739 - val_accuracy: 0.8632\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40225380659103394, 0.8533999919891357]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: make sure to use **AlphaDropout** instead of Dropout if you want to build a self-normalizing neural net using **SELU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-3. Monte Carlo(MC) Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7310240e-04, 2.4369091e-04, 1.1663308e-04, ..., 1.2146471e-01,\n",
       "        6.4492086e-04, 8.5218084e-01],\n",
       "       [1.7159666e-03, 3.7326376e-05, 9.4363898e-01, ..., 7.7966536e-07,\n",
       "        6.7002613e-05, 1.1051327e-06],\n",
       "       [5.0890376e-05, 9.9811846e-01, 3.6609094e-05, ..., 1.0060728e-06,\n",
       "        2.2292641e-06, 5.0586806e-07],\n",
       "       ...,\n",
       "       [4.7553228e-03, 2.4672574e-05, 3.8906292e-04, ..., 2.4750619e-04,\n",
       "        9.9006730e-01, 9.9389372e-06],\n",
       "       [6.9629961e-05, 9.8895609e-01, 1.3909070e-05, ..., 9.8531154e-06,\n",
       "        4.2570823e-06, 1.8107428e-05],\n",
       "       [1.0331578e-03, 3.0658569e-04, 9.3987747e-04, ..., 1.8467206e-01,\n",
       "        1.7861292e-02, 5.7091005e-03]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas = np.stack([model(x_test, training=True)for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.006, 0.   , 0.062, 0.   ,\n",
       "        0.931]], dtype=float32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:1]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.025, 0.   , 0.121, 0.001,\n",
       "       0.852], dtype=float32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.001, 0.001, 0.001, 0.   , 0.053, 0.001, 0.128, 0.002,\n",
       "       0.141], dtype=float32)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "y_std[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_proba.argmax(axis=1)\n",
    "accuracy = (y_pred == y_test).sum() / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(tf.keras.layers.Dropout):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "# Convert Dropout to MCDropout\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "mc_model = tf.keras.Sequential([MCDropout(layer.rate) if isinstance(layer, Dropout) else layer for layer in model.layers])\n",
    "mc_model.set_weights(model.get_weights()) # Here I didn't retrain the model for MCDropout just coping the weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "mc_dropout (MCDropout)       (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "mc_dropout_1 (MCDropout)     (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_dropout_2 (MCDropout)     (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.12, 0.  , 0.84]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model works without retrain\n",
    "cls()\n",
    "np.mean([mc_model.predict(x_test[:1]) for sample in range(100)], axis=0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-4. Max Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_constraint=tf.keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 1.3213 - accuracy: 0.6236 - val_loss: 0.9525 - val_accuracy: 0.7030\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.8392 - accuracy: 0.7277 - val_loss: 0.7687 - val_accuracy: 0.7578\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.7160 - accuracy: 0.7616 - val_loss: 0.6875 - val_accuracy: 0.7768\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6511 - accuracy: 0.7814 - val_loss: 0.6382 - val_accuracy: 0.7878\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6083 - accuracy: 0.7941 - val_loss: 0.6061 - val_accuracy: 0.7948\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.7865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6167654991149902, 0.7864999771118164]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaxNormDense = partial(tf.keras.layers.Dense,activation=\"elu\", kernel_initializer=\"he_normal\",kernel_constraint=tf.keras.constraints.max_norm(1.))\n",
    "cls()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(100),\n",
    "    MaxNormDense(100),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
