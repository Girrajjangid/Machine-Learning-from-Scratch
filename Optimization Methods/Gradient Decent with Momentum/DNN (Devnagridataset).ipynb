{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset():\n",
    "    path = '../../../DataSets/DevanagariHandwrittenCharacterDataset/Train/*'\n",
    "    train_l = []\n",
    "    train_d = [] # pixels 32*32\n",
    "    for label ,folder_name in enumerate(glob.glob(path)):\n",
    "        for image in (glob.glob(folder_name+'/*')):\n",
    "            imgdata = plt.imread(image).ravel()  # return (1024,) array  \n",
    "            train_d.append(imgdata)\n",
    "            train_l.append(label)\n",
    "    # takes 20 sec\n",
    "    \n",
    "    path = '../../../DataSets/DevanagariHandwrittenCharacterDataset/Test/*'\n",
    "    test_l = []\n",
    "    test_d = [] # pixels 32*32\n",
    "    for label ,folder_name in enumerate(glob.glob(path)):\n",
    "        for image in (glob.glob(folder_name+'/*')):\n",
    "            imgdata = plt.imread(image).ravel()  # return (1024,) array  \n",
    "            test_d.append(imgdata)\n",
    "            test_l.append(label)\n",
    "    # takes 10 sec\n",
    "\n",
    "    return np.vstack(train_d) , np.vstack(test_d) , np.vstack(train_l) , np.vstack(test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78200, 1024)\n",
      "(13800, 1024)\n",
      "(78200, 1)\n",
      "(13800, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# takes approx. 30sec\n",
    "X_train , X_test , y_train , y_test = loadDataset()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "for i in range(1,9):\n",
    "    plt.subplot(240+i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[4581+i,:].reshape(32,32), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.layers_n       = [] # no. of layers\n",
    "        self.theta_layers   = [] # hidden layers weight list\n",
    "        self.bias           = []\n",
    "        self.v0             = [] # exponential weight for momentum it also works as a bias \n",
    "        self.vb             = [] # exponential bias\n",
    "        self.activations    = [] # list of activations\n",
    "        self.dL_dA          = [] # derivative w.r.t activations\n",
    "        self.dL_dtheta      = [] # derivative w.r.t weights \n",
    "        self.dL_dbias       = [] # derivative w.r.t bias\n",
    "        self.itera          = [] # store iterations\n",
    "        self.csfun          = [] # store cost function values\n",
    "                \n",
    "    def add(self , neuron ):\n",
    "        self.layers_n.append(neuron)\n",
    "        \n",
    "    def one_hot_label(self , y):\n",
    "        one_hot_labels = np.zeros((y.shape[0] , self.layers_n[-1]))\n",
    "        for i in range(y.shape[0]):  \n",
    "            one_hot_labels[i, y[i] ] = 1\n",
    "        return one_hot_labels\n",
    "    \n",
    "    def fit(self , X , y , batch_size = 128 , alpha = 0.01 , epoche = 100,lmda = .01):\n",
    "        # He initialization\n",
    "        for i in range(len(self.layers_n)-1): \n",
    "            self.theta_layers.append(np.random.randn(self.layers_n[i],self.layers_n[i+1]) * np.sqrt(2/self.layers_n[i]))\n",
    "            self.v0.append(np.random.randn(self.layers_n[i],self.layers_n[i+1]) * np.sqrt(2/self.layers_n[i]))\n",
    "            \n",
    "            self.bias.append(np.random.randn(self.layers_n[i+1]) * np.sqrt(2/self.layers_n[i]) )\n",
    "            self.vb.append(np.random.randn(self.layers_n[i+1]) * np.sqrt(2/self.layers_n[i]) )\n",
    "        \n",
    "        return self.gradientDecent( X , y , batch_size , alpha , epoche )\n",
    "    \n",
    "    def softmax(self , activation , theta , bias):\n",
    "        exp = np.exp( np.dot( activation , theta ) + bias)\n",
    "        denominator = np.sum( exp , axis = 1)\n",
    "        s = list(map(lambda i : exp[:,i] / denominator , np.arange(self.layers_n[-1])))\n",
    "        return np.array(s).T\n",
    "    \n",
    "    def relu(self,activation,theta, bias):\n",
    "        q = (np.dot(activation , theta) + bias)\n",
    "        return np.clip(q , a_min=0 , a_max = q)\n",
    "\n",
    "    def forwardPropagation(self,X):\n",
    "        \n",
    "        self.activations    = []\n",
    "        \n",
    "        self.activations.append(X)\n",
    "        for i in range(len(self.layers_n)-2):\n",
    "            self.activations.append(self.relu(self.activations[i] , self.theta_layers[i] , self.bias[i]))\n",
    "                      \n",
    "        self.activations.append(self.softmax(self.activations[-1] , self.theta_layers[-1] , self.bias[-1]))\n",
    "        \n",
    "    def costFunction(self,X,y):\n",
    "        \n",
    "        self.y = self.one_hot_label(y)\n",
    "        self.forwardPropagation(X)\n",
    "        \n",
    "        #np.nan_to_num(self.activations[-1] , copy = False)\n",
    "        self.crossEntropy = self.y * np.log(self.activations[-1])\n",
    "        #np.nan_to_num(self.crossEntropy, copy=False)\n",
    "        \n",
    "        #regu = self.lmda * (np.sum(self.theta_layer1)**2 + np.sum(self.theta_layer2)**2 + np.sum(self.theta_layer3)**2 + np.sum(self.theta_layer4)**2)\n",
    "        return (1/X.shape[0] * -np.sum(self.crossEntropy)) #+ regu  # regu = 0 bcz lmda is zero \n",
    "      \n",
    "    \n",
    "    def backPropagation(self,X,y,alpha):\n",
    "        \n",
    "        self.dL_dA          = []\n",
    "        self.dL_dtheta      = []\n",
    "        self.dL_dbias       = []\n",
    "        \n",
    "        self.forwardPropagation(X)\n",
    "        \n",
    "        self.y_cap = self.activations[-1]\n",
    "        self.target_y = self.one_hot_label(y)\n",
    "        \n",
    "        self.dL_dA.append(self.y_cap - self.target_y)\n",
    "        \n",
    "        for i in range(len(self.layers_n)-2):   \n",
    "            \n",
    "            self.dL_dA.append( np.dot( self.dL_dA[i] , self.theta_layers[-1-i].T ) )\n",
    "        \n",
    "        for i in range(len(self.layers_n)-1):  \n",
    "            \n",
    "            self.dL_dtheta.append(1/X.shape[0] * (np.dot(self.activations[-2-i].T , self.dL_dA[i]))) \n",
    "            self.dL_dbias.append(1/X.shape[0] * self.dL_dA[i])\n",
    "        \n",
    "        for i in range(len(self.layers_n)-1):  \n",
    "            \n",
    "            self.theta_layers[i]    -= (alpha * self.dL_dtheta[-1-i])  \n",
    "            self.bias[-1-i]         -= (alpha * self.dL_dbias[i].sum(axis = 0))                  \n",
    "            \n",
    "            \n",
    "    def gradientDecent(self , X , y , batch , alpha , epoche  ):\n",
    "        i = 1\n",
    "        while i < epoche:\n",
    "            \n",
    "            index = np.random.randint(0 , X.shape[0] , size=(batch,))\n",
    "        \n",
    "            initial_cost = self.costFunction(X[index] , y[index] )\n",
    "       \n",
    "            self.backPropagation(X[index], y[index],alpha )\n",
    "                    \n",
    "            print('Iteration {} Cost function {}'.format(i , initial_cost ))    \n",
    "        \n",
    "            self.itera.append(i)\n",
    "            self.csfun.append(initial_cost)\n",
    "            i+=1\n",
    "            \n",
    "        final_cost = self.costFunction(X[index] , y[index] )\n",
    "        self.itera.append(i)\n",
    "        self.csfun.append(final_cost)\n",
    "            \n",
    "        \n",
    "            \n",
    "    def gradient_plot(self):\n",
    "        plt.plot(self.itera[10:],self.csfun[10:])\n",
    "         \n",
    "        \n",
    "    def accuracy(self , X , y):\n",
    "        self.forwardPropagation(X)\n",
    "        pred = np.argmax(self.activations[-1],axis=1)\n",
    "        c1 = 0\n",
    "        for i,j in enumerate(y):\n",
    "            if j == pred[i]:\n",
    "                c1+=1\n",
    "        print(\"Accuracy : \",(c1/y.shape[0])*100,'%')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Cost function 3.9773824455787823\n",
      "Iteration 2 Cost function 4.073333624030079\n",
      "Iteration 3 Cost function 4.058463037704657\n",
      "Iteration 4 Cost function 4.083383945995834\n",
      "Iteration 5 Cost function 4.037293129530783\n",
      "Iteration 6 Cost function 4.026803325860759\n",
      "Iteration 7 Cost function 4.075951401803641\n",
      "Iteration 8 Cost function 3.95867946966814\n",
      "Iteration 9 Cost function 3.9909659346585906\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "NN.add(1024)\n",
    "NN.add(46)\n",
    "NN.fit(X_train , y_train , batch_size=128 , alpha = 0.01 ,  epoche=10 , lmda = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "mini_batch_size = 20000\n",
    "\n",
    "np.random.seed(0)          \n",
    "m = X_train.shape[0]       \n",
    "mini_batches = []\n",
    "    \n",
    "permutation = list(np.random.permutation(m))\n",
    "shuffled_X = X_train[permutation,:]\n",
    "shuffled_Y = y_train[permutation].reshape((m,1))\n",
    "\n",
    "num_complete_minibatches = math.floor(m/mini_batch_size) \n",
    "num_complete_minibatches\n",
    "\n",
    "\n",
    "for k in range(0, num_complete_minibatches):\n",
    "    mini_batch_X = shuffled_X[k * mini_batch_size : (k + 1) * mini_batch_size, :]\n",
    "    mini_batch_Y = shuffled_Y[k * mini_batch_size : (k + 1) * mini_batch_size, :]\n",
    "    mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "    mini_batches.append(mini_batch)\n",
    "\n",
    "if m % mini_batch_size != 0:\n",
    "    mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size: , :]\n",
    "    mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size: , :]\n",
    "    mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "    mini_batches.append(mini_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1024) (20000, 1)\n",
      "(20000, 1024) (20000, 1)\n",
      "(20000, 1024) (20000, 1)\n",
      "(18200, 1024) (18200, 1)\n"
     ]
    }
   ],
   "source": [
    "for x,y in mini_batches:\n",
    "    print(x.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
