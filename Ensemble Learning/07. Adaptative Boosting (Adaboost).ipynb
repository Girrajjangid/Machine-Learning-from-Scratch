{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptative Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New weak learners are added sequentially that focus their training on the more difficult patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Boosting\n",
    "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers.\n",
    "\n",
    "This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model. Models are added until the training set is predicted perfectly or a maximum number of models are added.\n",
    "\n",
    "Boosting algorithms combine multiple low accuracy(or weak) models to create a high accuracy(or strong) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is AdaBoost\n",
    "\n",
    "AdaBoost was the first really successful boosting algorithm developed for binary classification. It is the best starting point for understanding boosting.\n",
    "\n",
    "AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers. AdaBoost is sensitive to noisy data and outliers\n",
    "\n",
    "AdaBoost is one of the first boosting algorithms to be adapted in solving practices. Adaboost helps you combine multiple “weak classifiers” into a single “strong classifier”. Here are some (fun) facts about Adaboost!\n",
    "\n",
    "1. The weak learners in AdaBoost are decision trees with a single split, called decision stumps.\n",
    "2. AdaBoost works by putting more weight on difficult to classify instances and less on those already handled well.\n",
    "3. AdaBoost algorithms can be used for both classification and regression problem.\n",
    "\n",
    "## AdaBoost Classifier\n",
    "\n",
    "Ada-boost or Adaptive Boosting is one of ensemble boosting classifier proposed by Yoav Freund and Robert Schapire in 1996. It combines multiple classifiers to increase the accuracy of classifiers. AdaBoost is an iterative ensemble method. AdaBoost classifier builds a strong classifier by combining multiple poorly performing classifiers so that you will get high accuracy strong classifier. The basic concept behind Adaboost is to set the weights of classifiers and training the data sample in each iteration such that it ensures the accurate predictions of unusual observations. Any machine learning algorithm can be used as base classifier if it accepts weights on the training set. Adaboost should meet two conditions:\n",
    "\n",
    "1. The classifier should be trained interactively on various weighed training examples.\n",
    "2. In each iteration, it tries to provide an excellent fit for these examples by minimizing training error.\n",
    "\n",
    "## How does the AdaBoost algorithm work?\n",
    "It works in the following steps:\n",
    "\n",
    "1. Initially, Adaboost selects a training subset randomly.\n",
    "2. It iteratively trains the AdaBoost machine learning model by selecting the training set based on the accurate prediction of the last training.\n",
    "3. It assigns the higher weight to wrong classified observations so that in the next iteration these observations will get the high probability for classification.\n",
    "4. Also, It assigns the weight to the trained classifier in each iteration according to the accuracy of the classifier. The more accurate classifier will get high weight.\n",
    "5. This process iterate until the complete training data fits without any error or until reached to the specified maximum number of estimators.\n",
    "6. To classify, perform a \"vote\" across all of the learning algorithms you built.\n",
    "\n",
    "<img src='f.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=.3,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23d3cecd400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(y_train).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23d3cc3ce80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(y_test).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"The most important parameters are base_estimator, n_estimators, and learning_rate.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**base_estimator:** It is a weak learner used to train the model. It uses DecisionTreeClassifier as default weak learner for training purpose. You can also specify different machine learning algorithms.\n",
    "\n",
    "**n_estimators:** Number of weak learners to train iteratively.\n",
    "\n",
    "**learning_rate:** It contributes to the weights of weak learners. It uses 1 as a default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = abc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22, 0.04, 0.4 , 0.34])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using different BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(probability=True, kernel= 'linear' )\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=50,learning_rate=1,base_estimator=svc)\n",
    "\n",
    "abc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = abc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros\n",
    "\n",
    "AdaBoost is easy to implement. It iteratively corrects the mistakes of the weak classifier and improves accuracy by combining weak learners. You can use many base classifiers with AdaBoost. AdaBoost is not prone to overfitting. This can be found out via experiment results, but there is no concrete reason available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cons\n",
    "AdaBoost is sensitive to noise data. It is highly affected by outliers because it tries to fit each point perfectly. AdaBoost is slower compared to XGBoost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
