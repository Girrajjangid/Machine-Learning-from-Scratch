{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Perceptron is an algorithm invented in 1957 by Frank Rosenblatt, a few years before the first SVM. It is widely known because it is the building block of a simple neural network: the multilayer perceptron. The goal of the Perceptron is to find a hyperplane that can separate a linearly separable data set. Once the hyperplane is found, it is used to perform binary classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given augmented vectors $\n",
    "\\mathbf{x}=\\left(x_{0}, x_{1}, \\ldots, x_{n}\\right) \\text { and } \\mathbf{w}=\\left(w_{0}, w_{1}, \\ldots, w_{n}\\right)\n",
    "$ , the Perceptron uses the  hypothesis function to classify a data point \n",
    "\n",
    "x = features\n",
    "\n",
    "w = parameters\n",
    "\n",
    "sign = class [-1,1]\n",
    "$$\n",
    "h\\left(\\mathbf{x}_{i}\\right)=\\operatorname{sign}\\left(\\mathbf{w} \\cdot \\mathbf{x}_{i}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron learning algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a training set  of  N-dimensional training examples $(X_{i},Y_{i})$  , the **Perceptron Learning Algorithm** (PLA) tries to find a hypothesis function 'h' that predicts the label $y_{i}$ of every $x_{i}$ correctly.  \n",
    "\n",
    "The hypothesis function of the Perceptron is $h\\left(\\mathbf{x}_{i}\\right)=\\operatorname{sign}\\left(\\mathbf{w} \\cdot \\mathbf{x}_{i}\\right)$, and we know that 'w.x' is just the equation of a hyperplane. We can then say that the set 'H' hypothesis functions is the set of 'n-1' dimensional hyperplanes ( because a hyperplane has one dimension less than its ambient space). \n",
    "\n",
    "What is important to understand here is that the only unknown value is 'w'. It means that the goal of the algorithm is to find a value for 'w'. You find 'w'; you have a hyperplane. There is an infinite number of hyperplanes (you can give any value to ), so there is an infinity of hypothesis functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be written more formally this way:  \n",
    "\n",
    "Given a training set: $\\mathcal{D}=\\left\\{\\left(\\mathbf{x}_{i}, y_{i}\\right) | \\mathbf{x}_{i} \\in \\mathbb{R}^{n}, y_{i} \\in\\{-1,1\\}\\right\\}_{i=1}^{m} \\text { and a set } \\mathcal{H}$ of hypothesis functions. \n",
    "\n",
    "Find $h \\in \\mathcal{H} \\text { such that } h\\left(\\mathbf{x}_{i}\\right)=y_{i} \\text { for every } \\mathbf{x}_{i}$\n",
    "\n",
    "This is equivalent to: \n",
    "\n",
    "Given a training set: $\\mathcal{D}=\\left\\{\\left(\\mathbf{x}_{i}, y_{i}\\right) | \\mathbf{x}_{i} \\in \\mathbb{R}^{n}, y_{i} \\in\\{-1,1\\}\\right\\}_{i=1}^{m} \\text { and a set } \\mathcal{H}$ of hypothesis functions. \n",
    "\n",
    "Find $\\mathbf{w}=\\left(w_{0}, w_{1}, \\ldots, w_{n}\\right) \\text { such that } \\operatorname{sign}\\left(\\mathbf{w} \\cdot \\mathbf{x}_{i}\\right)=y_{i} \\text { for every } \\mathbf{x}_{i}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "The PLA is a very simple algorithm, and can be summarized this way: \n",
    "1. Start with a random hyperplane (defined by a vector ) and use it to classify the data.  \n",
    "2. Pick a misclassified example and select another hyperplane by updating the value of , hoping it will work better at classifying this example (this is called the update rule).  \n",
    "3. Classify the data with this new hyperplane. \n",
    "4. Repeat steps 2 and 3 until there is no misclassified example. \n",
    "\n",
    "Once the process is over, you have a hyperplane that separates the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
