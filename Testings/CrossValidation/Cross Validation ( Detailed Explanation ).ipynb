{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a technique that is used for the assessment of how the results of statistical analysis generalize to an independent data set. Cross-validation is largely used in settings where the target is prediction and it is necessary to estimate the accuracy of the performance of a predictive model. The prime reason for the use of cross-validation rather than conventional validation is that there is not enough data available for partitioning them into separate training and test sets (as in conventional validation). This results in a loss of testing and modeling capability.\n",
    "\n",
    "Cross-validation is also known as rotation estimation.\n",
    "\n",
    "Before testing out any model, would you not like to test it with an independent dataset? Normally, in any prediction problem, your model works on a known dataset. You also call it the training dataset. However, in real time, your model will have to work on an unknown dataset.\n",
    "\n",
    "Under such circumstances, will your model be able to predict the outcome correctly? You do not know unless you test your model on a random dataset. This testing is what we refer to as cross validation. Once your model passes this test, it is fit to work anywhere\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose ?\n",
    "\n",
    "The purpose of cross validation is to assess how our prediction model performs with an unknown dataset. We shall look at it from a layman’s point of view.\n",
    "\n",
    "Suppose we are learning how to drive a car. Now, anyone can drive a car on an empty road. The real test is how we drive in demanding traffic. It is why the trainers train us on roads that have traffic so that we get used to it.\n",
    "\n",
    "Therefore, when it is time for us actually to drive our car, we are prepared to do so without the trainer sitting by your side to guide us. We are ready to handle any situation, the like of which we might not have encountered before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Types of Cross Validation in Machine Learning\n",
    "There are two types of cross validation:\n",
    "\n",
    "## (A) Exhaustive Cross Validation – \n",
    "This method involves testing the machine on all possible ways by dividing the original sample into training and validation sets.\n",
    "\n",
    "There are two types of exhaustive cross validation in machine learning\n",
    "\n",
    "### 1. Leave-p-out Cross Validation (LpO CV)\n",
    "\n",
    "Here we have a set of observations of which we select a random number, say ‘p.’ Treat the ‘p’ observations as our validating set and the remaining as our training sets.\n",
    "\n",
    "There is a disadvantage because the cross validation process can become a lengthy one. It depends on the number of observations in the original sample and our chosen value of ‘p.’\n",
    "\n",
    "### 2. Leave-one-out Cross Validation (LOOCV)\n",
    "\n",
    "This method of cross validation is similar to the LpOCV except for the fact that ‘p’ = 1. The advantage is that we save on the time factor.\n",
    "\n",
    "However, if the number of observations in the original sample is large, it can still take a lot of time. Nevertheless, it is quicker than the LpO CV method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Non-Exhaustive Cross Validation – \n",
    "Here, we do not split the original sample into all the possible permutations and combinations. Instead we split only one time.\n",
    "\n",
    "As the name suggests we do not compute all the ways of splitting the original sample. Hence, we can also call it the approximations of the LpO CV.\n",
    "\n",
    "### 1. K-fold Cross Validation\n",
    "\n",
    "This method envisages partitioning of the original sample into ‘k’ equal sized sub-samples. We take out a single sample from these ‘k’ samples and use it as the validation data for testing our model. We treat the remaining ‘k-1’ samples as our training data.\n",
    "\n",
    "We repeat the cross validation process ‘k’ times using each ‘k’ sample as the validation data once. Take an average of the ‘k’ number of results to produce our estimation. The advantage of this method is that we use all the observations for both training and validation, and each sample for validation once.\n",
    "\n",
    "### 2. Stratified K-fold Cross Validation\n",
    "This procedure is a variation of the method described above. The difference is that we select the folds in such a way that we have equal mean response value in all the folds.\n",
    "\n",
    "#### Stratification: \n",
    "It is the process of rearranging the data as to ensure each fold is a good representative of the whole. For example in a binary classification problem where each class comprises 50% of the data, it is best to arrange the data such that in every fold, each class comprises around half the instances.\n",
    "\n",
    "**Stratification is generally a better scheme, both in terms of bias and variance, when compared to regular cross-validation.**\n",
    "\n",
    "The folds are stratified in such a manner that each fold contains same proportion of labels as the original data\n",
    "\n",
    "### 3. Holdout Method\n",
    "\n",
    "The holdout cross validation method is the simplest of all. In this method, we randomly assign data points to two sets. The size of the sets does not matter.\n",
    "\n",
    "Treat the smaller set say ‘d0’ as the testing set and the larger one, ‘d1’ as the training set. We train our model on the d0 set and test it on the d1. There is a disadvantage because we do a single run. It can give misleading results.\n",
    "\n",
    "### 4. Monte Carlo Cross Validation\n",
    "\n",
    "This test is a better version of the holdout test. We split the datasets randomly into training data and validation data. For each split, we assess the predictive accuracy using the respective training and validation data.\n",
    "\n",
    "Finally, we average the results over all the splits. The advantage of this method is that the proportion of the validation or training split is not dependent on the number of folds (K-fold test). However, there is a disadvantage as well.\n",
    "\n",
    "There are chances that we might miss out some observations whereas we might select some observations more than once. Under such circumstances, the validation subsets could overlap. We also refer to this procedure as Repeated Random Sub-sampling method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Importance of Cross Validation in Machine Learning\n",
    "\n",
    "When our original validation partition does not represent the overall population, we get a model that might appear to have a high degree of accuracy.\n",
    "\n",
    "However, in reality, it will not be much useful because it can work with a particular set of data. The moment it finds data outside its purview, the machine cannot recognize it thereby resulting in poor accuracy.\n",
    "\n",
    "When we use cross validation in machine learning, we verify how accurate our model is on multiple and different subsets of data. Therefore, we ensure that it generalizes well to the data that we collect in the future. It improves the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of Cross Validation\n",
    "We have seen what cross validation in machine learning is and understood the importance of the concept. It is a vital aspect of machine learning, but it has its limitations.\n",
    "\n",
    "(a) In an ideal world, the cross validation will yield meaningful and accurate results. However, the world is not perfect. You never know what kind of data the model might encounter in the future.\n",
    "\n",
    "(b) Usually, in predictive modelling, the structure you study evolves over a period. Hence, you can experience differences between the training and validation sets. Let us consider you have a model that predicts stock values.\n",
    "\n",
    "You have trained the model using data of the previous five years. Would it be realistic to expect accurate predictions over the next five-year period?\n",
    "\n",
    "(c) Here is another example where the limitation of the cross validation process comes to the fore. You develop a model for predicting the individual’s risk of suffering from a particular ailment.\n",
    "\n",
    "However, you train the model using data from a study involving a specific section of the population. The moment you apply the model to the general population, the results could vary a lot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Cross Validation\n",
    "(a) You can use cross validation to compare the performances of a set of predictive modelling procedures.\n",
    "\n",
    "(b) It has excellent use in the field of medical research. Consider that we use the expression levels of a certain number of proteins, say 15 for predicting whether a cancer patient will respond to a specific drug.\n",
    "\n",
    "The ideal way is to determine which subset of the 15 features produce the ideal predictive model. Using cross validation, you can determine the exact subset that provides the best results.\n",
    "\n",
    "(c) Recently, data analysts have used cross validation in the field of medical statistics. These procedures are useful in the meta-analysis.\n",
    "\n",
    "\n",
    "Resource : https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "Generally we can use the K-Fold Cross validation and the LOOCV processes to solve overfitting and underfitting problem in python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
